# 作业1:线性模型和支持向量机

**姓名**: 杨憬晗  
**学号**: 2022010808

---

## 线性模型与梯度下降

### 2.1 特征归一化

在实际任务中，若各维特征的量级差异较大，梯度下降的收敛会显著变慢；同时，在使用正则化时，量级较大的特征对正则项影响更强。因此需要进行特征归一化。常用做法是在训练集上对每个特征进行仿射变换，将其映射到区间[0,1]；并对测试集施加与训练集一致的变换。

#### 2.1.1 补全函数split_data，将数据集划分为训练集与测试集

**实现思路**：
- 根据`split_size`中的比例，依次计算每个划分的样本数量
- 使用索引切片将数据集划分为多个部分
- 处理最后一个划分以确保包含所有剩余样本

**代码实现**：
```python
start_idx = 0
for ratio in split_size:
    # 计算当前划分的样本数量
    split_num = int(num_instances * ratio)
    end_idx = start_idx + split_num
    
    # 处理最后一个划分，确保包含所有剩余样本
    if end_idx > num_instances or ratio == split_size[-1]:
        end_idx = num_instances
    
    # 划分数据
    X_list.append(X[start_idx:end_idx])
    y_list.append(y[start_idx:end_idx])
    
    start_idx = end_idx

return X_list, y_list
```

**关键点**：
- 使用累积索引方式进行数据划分
- 最后一个划分需要包含所有剩余样本，避免因浮点数计算导致的样本丢失

#### 2.1.2 补全函数feature_normalization，实现特征归一化

**实现思路**：
- 在训练集上计算每个特征的最小值和最大值
- 使用Min-Max归一化公式: \( x_{norm} = \frac{x - x_{min}}{x_{max} - x_{min}} \)
- 对测试集使用训练集的最小值和最大值进行相同的变换

**代码实现**：
```python
# 从训练集计算每个特征的最小值和最大值
train_min = np.min(train, axis=0)
train_max = np.max(train, axis=0)

# 避免除零错误：如果最大值等于最小值，说明该特征为常数
# 此时将范围设为1，保持归一化后的值不变
range_vals = train_max - train_min
range_vals[range_vals == 0] = 1  # 避免除零

# 将训练集归一化到 [0, 1]
train_normalized = (train - train_min) / range_vals

# 对测试集使用训练集的最小值和最大值进行相同的变换
test_normalized = (test - train_min) / range_vals

return train_normalized, test_normalized
```

**关键点**：
1. **统计量的计算**：所有归一化参数（最小值、最大值）都从训练集计算得出
2. **测试集一致性**：测试集必须使用训练集的统计量进行变换，确保分布一致
3. **边界情况处理**：当某个特征的最大值等于最小值时（常数特征），设置范围为1以避免除零错误
4. **向量化操作**：使用numpy的广播机制，对所有特征同时进行归一化，提高效率

**理论依据**：
- Min-Max归一化将特征线性映射到[0,1]区间
- 通过仿射变换 \( x' = \frac{x - min}{max - min} \) 实现
- 保证所有特征处于相同量级，有利于梯度下降的收敛
- 在正则化时，避免量级大的特征主导正则项

---

### 2.2 目标函数与梯度

岭回归(Ridge Regression)是在线性回归的基础上加入L2正则化，目的是防止过拟合并提高模型的泛化能力。

#### 2.2.1 写出\( J(\theta) \)的矩阵形式表达式

**已知条件**：
- 设计矩阵：\( X \in \mathbb{R}^{m \times (d+1)} \)，其中第 \( i \) 行为 \( x_i^\top \)
- 标签向量：\( y \in \mathbb{R}^m \)
- 参数向量：\( \theta \in \mathbb{R}^{d+1} \)
- 正则化系数：\( \lambda > 0 \)

**目标函数**：

岭回归的目标函数为：
\[
J(\theta) = \frac{1}{m} \| X\theta - y \|^2 + \lambda \| \theta \|^2
\]

展开为矩阵形式：
\[
J(\theta) = \frac{1}{m}(X\theta - y)^\top (X\theta - y) + \lambda \theta^\top \theta
\]

其中：
- 第一项 \( \frac{1}{m}(X\theta - y)^\top (X\theta - y) \) 是均方误差损失
- 第二项 \( \lambda \theta^\top \theta \) 是L2正则化项

#### 2.2.2 补全函数compute_regularized_square_loss，计算\( J(\theta) \)

**实现目标**：根据 \( J(\theta) = \frac{1}{m}(X\theta - y)^\top (X\theta - y) + \lambda \theta^\top \theta \) 实现目标函数。

**代码实现**：
```python
num_instances = X.shape[0]

# 计算预测值
predictions = np.dot(X, theta)

# 计算残差
residuals = predictions - y

# 计算平方损失: (1/m) * ||Xθ - y||²
square_loss = np.dot(residuals, residuals) / num_instances

# 计算正则化项: λ * ||θ||²
regularization = lambda_reg * np.dot(theta, theta)

# 目标函数 J(θ)
loss = square_loss + regularization

return loss
```

**关键点**：
- 使用 `np.dot` 进行向量化计算

#### 2.2.3 推导\( J(\theta) \)的梯度

**推导过程**：

对 \( J(\theta) = \frac{1}{m}(X\theta - y)^\top(X\theta - y) + \lambda \theta^\top\theta \) 求梯度。

分别对两项求导：

1. **对均方误差项求导**：
   \[
   \frac{\partial}{\partial\theta}\left[\frac{1}{m}(X\theta - y)^\top(X\theta - y)\right] = \frac{2}{m}X^\top(X\theta - y)
   \]

2. **对正则化项求导**：
   \[
   \frac{\partial}{\partial\theta}\left[\lambda\theta^\top\theta\right] = 2\lambda\theta
   \]

**梯度表达式**：
\[
\nabla J(\theta) = \frac{2}{m}X^\top(X\theta - y) + 2\lambda\theta
\]

**梯度含义**：
- \( \frac{2}{m}X^\top(X\theta - y) \)：均方误差项的梯度，将残差投影到特征空间
- \( 2\lambda\theta \)：正则化项的梯度，使参数向零收缩，防止过拟合
- 梯度下降更新：\( \theta_{t+1} = \theta_t - \alpha \nabla J(\theta_t) \)

#### 2.2.4 补全函数compute_regularized_square_loss_gradient，实现\( J(\theta) \)的梯度

**实现目标**： \( \nabla J(\theta) = \frac{2}{m}X^\top(X\theta - y) + 2\lambda\theta \)

**代码实现**：
```python
num_instances = X.shape[0]

# 计算预测值
predictions = np.dot(X, theta)

# 计算残差
residuals = predictions - y

# 计算梯度: (2/m) * X^T(Xθ - y) + 2λθ
grad = 2 * np.dot(X.T, residuals) / num_instances + 2 * lambda_reg * theta

return grad
```

**关键点**：
- 使用 `X.T` 进行矩阵转置
- 向量化实现，无需循环

---

### 2.3 梯度下降

#### 2.3.1 用梯度写出目标函数值变化的近似表达式

**问题**：在最小化 \( J(\theta) \) 时，考虑从当前参数 \( \theta \) 沿方向 \( h \in \mathbb{R}^{d+1} \) 前进一步至 \( \theta + \eta h \)，其中 \( \eta > 0 \) 为步长。请用梯度写出目标函数值变化的近似表达式 \( J(\theta + \eta h) - J(\theta) \)，思考 \( h \) 为哪一前进方向时目标函数下降最快，并据此写出梯度下降中更新 \( \theta \) 的表达式。

**1. 目标函数值变化的近似表达式**

对光滑函数 \( J(\theta) \) 在点 \( \theta \) 处进行一阶泰勒展开：
\[
J(\theta + \eta h) \approx J(\theta) + \eta \nabla J(\theta)^\top h
\]

因此，目标函数值的变化近似为：
\[
J(\theta + \eta h) - J(\theta) \approx \eta \nabla J(\theta)^\top h
\]

**2. 下降最快的方向**

为使目标函数下降，需要 \( \nabla J(\theta)^\top h < 0 \)。

要使下降最快，应使 \( \nabla J(\theta)^\top h \) 最小。由柯西-施瓦茨不等式：
\[
\nabla J(\theta)^\top h \geq -\|\nabla J(\theta)\| \cdot \|h\|
\]

当且仅当 \( h = -\nabla J(\theta) \) 时等号成立，即**负梯度方向**是目标函数下降最快的方向。

**3. 梯度下降更新规则**

梯度下降法的参数更新公式为：
\[
\theta := \theta - \eta \nabla J(\theta)
\]

对于岭回归，梯度为 \( \nabla J(\theta) = \frac{2}{m} X^\top (X\theta - y) + 2\lambda \theta \)，因此更新规则为：
\[
\theta := \theta - \eta \left[\frac{2}{m} X^\top (X\theta - y) + 2\lambda \theta\right]
\]

其中 \( \eta \) 是学习率（步长）。

#### 2.3.2 补全函数grad_descent，实现全批量梯度下降算法

**算法流程**：

全批量梯度下降（Batch Gradient Descent）在每次迭代中使用全部训练数据计算梯度并更新参数。

**代码实现**：
```python
for i in range(num_iter):
    # 计算当前损失
    loss_hist[i] = compute_regularized_square_loss(X, y, theta, lambda_reg)
    
    # 计算梯度
    grad = compute_regularized_square_loss_gradient(X, y, theta, lambda_reg)
    
    # 梯度检查
    if check_gradient:
        if not grad_checker(X, y, theta, lambda_reg):
            print(f"警告：第{i}次迭代梯度检查未通过")
    
    # 更新参数：θ := θ - α * ∇J(θ)
    theta = theta - alpha * grad
    
    # 保存参数历史
    theta_hist[i + 1] = theta

return theta_hist, loss_hist
```

**关键点**：
- 每次迭代使用**全部训练数据**计算梯度
- 按照梯度下降公式 \( \theta := \theta - \alpha \nabla J(\theta) \) 更新参数
- 记录每次迭代的损失值和参数值，用于后续分析
- 可选择性地进行梯度检查以验证梯度计算的正确性

**算法特点**：
- **优点**：每次迭代方向准确，收敛稳定
- **缺点**：数据量大时计算代价高，每次迭代需要遍历全部数据
- **适用场景**：中小规模数据集，或需要精确收敛的场景

#### 2.3.3 步长选择实验

**实验目的**：研究不同步长对梯度下降收敛性能的影响。

**实验设置**：
- 固定正则化系数 \( \lambda = 0 \)
- 测试步长：\( \eta \in \{0.01, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.5\} \)
- 迭代次数：1000次
- 观察目标函数 \( J(\theta) \) 随迭代次数的变化
- 数据集：200个样本，48个特征（训练集160，测试集40）

**实验脚本**：
```bash
python experiment_step_size.py
```

**实验结果**：

运行实验脚本后，生成不同步长下的收敛曲线对比图：

![步长对比实验结果](sgd/step_size_comparison.png)

**实际结果分析**：

| 步长 \( \eta \) | 初始损失 | 最终损失 | 收敛情况 | 损失下降 | 特点 |
|:---:|:---:|:---:|:---:|:---:|:---|
| 0.01 | 6.897 | 2.839 | ✓ 收敛 | 58.84% | 步长较小，收敛稳定但速度慢 |
| 0.05 | 6.897 | 2.306 | ✓ 收敛 | 66.57% | **最优步长**，收敛稳定且下降充分 |
| 0.06 | 6.897 | 1.14×10¹²¹ | ✗ 发散 | - | 刚超过临界值，数值爆炸 |
| 0.07 | 6.897 | NaN | ✗ 发散 | - | 步长过大，严重发散 |
| 0.08 | 6.897 | NaN | ✗ 发散 | - | 步长过大，严重发散 |
| 0.09 | 6.897 | NaN | ✗ 发散 | - | 步长过大，严重发散 |
| 0.1 | 6.897 | NaN | ✗ 发散 | - | 步长过大，严重发散 |
| 0.5 | 6.897 | NaN | ✗ 发散 | - | 步长过大，严重发散 |

**结论**：

1. **收敛最快的步长**：\( \eta = 0.05 \)
   - 在保证收敛的所有步长中，该步长实现了最大的损失下降（66.57%）
   - 相比 \( \eta = 0.01 \)，收敛更充分且速度更快
   - 是本数据集上的**最优选择**

2. **导致发散的步长**：\( \eta \geq 0.06 \)
   - 当 \( \eta = 0.06 \) 时，参数开始爆炸性增长，损失达到 \( 10^{121} \) 量级
   - 从 \( \eta = 0.07 \) 开始，直接导致NaN（数值溢出）
   - 通过细化实验，确定步长上界非常接近 \( \eta_{max} \approx 0.055 \)（介于0.05和0.06之间）

**理论分析**：

对于梯度下降，步长需要满足一定的上界条件。对于光滑且Lipschitz连续的目标函数，梯度下降的收敛要求：
\[
\eta < \frac{2}{L}
\]
其中 \( L \) 是目标函数梯度的Lipschitz常数。

在本实验中：
- 数据维度较高（48个特征），且未进行正则化（\( \lambda = 0 \)）
- 这导致梯度的Lipschitz常数 \( L \) 较大，步长上界相应变小
- 通过细化实验，精确定位步长上界约为 \( \eta_{max} \approx 0.055 \)（介于0.05和0.06之间）
- 当 \( \eta = 0.06 \) 时，参数更新已超过临界点，损失在几次迭代后爆炸至 \( 10^{121} \) 量级
- 从 \( \eta = 0.07 \) 开始，梯度爆炸（overflow）导致立即出现NaN

**关键观察**：

1. **步长敏感性**：
   - 仅0.01和0.05两个步长能够收敛，选择范围极其狭窄
   - 步长从0.05增加到0.06（仅增加20%），立即从收敛变为发散
   - \( \eta = 0.06 \) 时损失爆炸至 \( 10^{121} \)，\( \eta = 0.07 \) 时直接NaN
   - 说明该问题对步长的选择**极度敏感**，步长上界的容忍度几乎为零

2. **收敛曲线特征**：
   - \( \eta = 0.01 \)：收敛平稳，但1000次迭代后损失仍为2.839
   - \( \eta = 0.05 \)：收敛更快，1000次迭代后损失降至2.306
   - 在对数尺度图中，两条收敛曲线呈现近似指数下降趋势

3. **实践启示**：
   - 高维数据（特征数多）往往需要较小的学习率
   - 无正则化时，目标函数的条件数可能很差，需要更谨慎选择步长
   - 实际应用中建议从小步长开始尝试，逐步增大直到观察到不稳定现象
   - 可使用学习率衰减策略，初期使用较大步长加速收敛，后期使用小步长精细调整

